{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_practise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafi007akhtar/coursera-tensorflow/blob/master/NLP_practise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2M2vE_nV94b",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer practise\n",
        "\n",
        "Colab Notebook containing code for basic NLP practise using Keras.\n",
        "\n",
        "* Topics covered:\n",
        "  - word index\n",
        "  - sequences\n",
        "  - out-of-vocabs\n",
        "  - padding\n",
        "\n",
        "* Class used: `Tokenizer`\n",
        "\n",
        "* Functions / methods used\n",
        "  - `fit_on_texts`\n",
        "  - `texts_to_sequences`\n",
        "  - `pad_sequences`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbuTUXgoWBhw",
        "colab_type": "text"
      },
      "source": [
        "## Import `tokenizer` from `keras`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zox2aNn4YJV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFuIGL27WIYD",
        "colab_type": "text"
      },
      "source": [
        "## Generate word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWwyML2YeZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider the following list of sentences\n",
        "sentences = [\n",
        "    \"winter is coming\",\n",
        "    \"winter is here\"\n",
        "]\n",
        "\n",
        "# create an instance of the Tokenizer class\n",
        "tkz = Tokenizer(num_words = 100, oov_token=\"<missing>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpMuH5mWeba",
        "colab_type": "text"
      },
      "source": [
        "Parameters used in the above object creation:\n",
        "- `num_words`: The maximum number of words the tokenizer would look for in the sentences\n",
        "- `oov_token`: replace unrecognized  (\"out-of-vocabulary\") words with this token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2NGZBNqZIpR",
        "colab_type": "code",
        "outputId": "a90194b3-1bf8-431e-b32d-b647a515856d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tkz.fit_on_texts(sentences)  # creates a list with words and their indices\n",
        "ind = tkz.word_index  # returns a dictionary with words and their indices\n",
        "print(ind)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<missing>': 1, 'winter': 2, 'is': 3, 'coming': 4, 'here': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7alGj_IcYe9P",
        "colab_type": "text"
      },
      "source": [
        "## Generate sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHJoRcZZUQA",
        "colab_type": "code",
        "outputId": "e6c2e3ca-afad-4b86-a070-7511e133b019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq = tkz.texts_to_sequences(sentences) # returns a list with each word replaced by its index from the word_index\n",
        "seq"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4], [2, 3, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olPtqP-cY9c0",
        "colab_type": "text"
      },
      "source": [
        "## Missing text\n",
        "\n",
        "Here is where the `oov_token`parameter will come into play. The sequence will replace any out-of-vocab word with the value of the above parameter.\n",
        "\n",
        "If the `oov_token` parameter was not provided above, the unrecognized words would have been ignored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owB4X122aNP1",
        "colab_type": "code",
        "outputId": "1026178b-699d-41ed-c956-77d0d2695e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_text = [\n",
        "    \"when winter comes and\",\n",
        "    \"here lies my grave\",\n",
        "    \"the lone wolf dies but the pack survives\"\n",
        "]\n",
        "seq = tkz.texts_to_sequences(test_text)\n",
        "seq"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 1, 1], [5, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYp6uxBztCEc",
        "colab_type": "code",
        "outputId": "af2b28ef-3a33-4845-b2cf-6996272ff2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tkz.fit_on_texts(test_text)\n",
        "ind = tkz.word_index\n",
        "print(ind)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<missing>': 1, 'winter': 2, 'is': 3, 'here': 4, 'the': 5, 'coming': 6, 'when': 7, 'comes': 8, 'and': 9, 'lies': 10, 'my': 11, 'grave': 12, 'lone': 13, 'wolf': 14, 'dies': 15, 'but': 16, 'pack': 17, 'survives': 18}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS099D6-ZvON",
        "colab_type": "text"
      },
      "source": [
        "## Padding\n",
        "\n",
        "Here, extra info is added to the sequence sublists so that their lengths are uniform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1crM_tThtXnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pads = pad_sequences(seq) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPcmh9gfzj4u",
        "colab_type": "code",
        "outputId": "b06445c6-75b4-4c49-c313-6496a09c4e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pads"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  6,  2,  7,  8],\n",
              "       [ 0,  0,  0,  0,  4,  9, 10, 11],\n",
              "       [ 1,  1,  1,  1,  1,  1,  1,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAekwwNaEEw",
        "colab_type": "text"
      },
      "source": [
        "Additional parameters that can be used:\n",
        "- use `padding=\"post\"` for padding at the end of the matrix; \n",
        "- use `maxlen=5` for a maximum of 5 words; you will lose from the beginning\n",
        "- use `truncating=\"post\"` along with maxlen to lose extra info from the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-PZhv89zo5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}