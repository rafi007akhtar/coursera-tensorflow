{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafi007akhtar/coursera-tensorflow/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "04e05f2e-31dc-4c16-9ee7-c7538fa9da48"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3 (\n",
        "    input_shape = (150, 150, 3),\n",
        "    include_top = False,\n",
        "    weights = None\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 20:00:46--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  98.4MB/s    in 0.9s    \n",
            "\n",
            "2019-06-12 20:00:47 (98.4 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34aba439-5a51-4a8c-d857-89cbca76d8a5"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer(\"mixed10\")\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))\n",
        "# NOTE: Output doesn't match expected output\n",
        "# Reason: I'm using mixed10 instead of mixed7 layer"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 3, 3, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11441
        },
        "outputId": "e407115b-dcd0-415a-ce72-9fea79caf418"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation=\"sigmoid\")(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = \"binary_crossentropy\", \n",
        "              metrics = [\"acc\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n",
        "\n",
        "# NOTE: Ouput doesn't match expected o/p since I'm using mixed10 layer instead of mixed7 layer\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 18432)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         18875392    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 40,679,201\n",
            "Trainable params: 18,876,417\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2e576b5b-2f22-46ef-c5ee-8c0a8f2a1fd1"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 20:09:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  80.6MB/s    in 1.8s    \n",
            "\n",
            "2019-06-12 20:09:30 (80.6 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-12 20:09:31--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  43.5MB/s    in 0.3s    \n",
            "\n",
            "2019-06-12 20:09:31 (43.5 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3794dc0-7ba5-48e0-95b0-021d6185e56d"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, \"horses\")\n",
        "train_humans_dir = os.path.join(train_dir, \"humans\")\n",
        "validation_horses_dir = os.path.join(validation_dir, \"horses\")\n",
        "validation_humans_dir = os.path.join(validation_dir, \"humans\")\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef8165cf-2646-46e0-e9ab-a3691b033474"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2, \n",
        "    height_shift_range = 0.2, \n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True    \n",
        ")\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 32,\n",
        "    class_mode = \"binary\",\n",
        "    target_size = (150, 150)\n",
        ")\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size = 16,\n",
        "    class_mode = \"binary\",\n",
        "    target_size = (150, 150)    \n",
        ")\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5117
        },
        "outputId": "588d64c5-6ba7-4e7b-a565-e6ace938e8bf"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 128,\n",
        "    epochs = 100,\n",
        "    validation_steps = 64,\n",
        "    verbose = 2,\n",
        "    callbacks = [callbacks]\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.2767 - acc: 0.9375\n",
            " - 12s - loss: 0.1628 - acc: 0.9747 - val_loss: 0.2767 - val_acc: 0.9375\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0812 - acc: 0.9648\n",
            " - 11s - loss: 0.1348 - acc: 0.9659 - val_loss: 0.0812 - val_acc: 0.9648\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 4.2931e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.1164 - acc: 0.9640 - val_loss: 4.2931e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.7890 - acc: 0.8672\n",
            " - 11s - loss: 0.2675 - acc: 0.9659 - val_loss: 0.7890 - val_acc: 0.8672\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1077 - acc: 0.9883\n",
            " - 11s - loss: 0.1334 - acc: 0.9688 - val_loss: 0.1077 - val_acc: 0.9883\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0663 - acc: 0.9844\n",
            " - 11s - loss: 0.1511 - acc: 0.9611 - val_loss: 0.0663 - val_acc: 0.9844\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 4.3016e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.1136 - acc: 0.9659 - val_loss: 4.3016e-04 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0230 - acc: 0.9922\n",
            " - 11s - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0230 - val_acc: 0.9922\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0292 - acc: 0.9844\n",
            " - 11s - loss: 0.2399 - acc: 0.9757 - val_loss: 0.0292 - val_acc: 0.9844\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0171 - acc: 0.9961\n",
            " - 11s - loss: 0.1000 - acc: 0.9737 - val_loss: 0.0171 - val_acc: 0.9961\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.1032 - acc: 0.9727\n",
            " - 11s - loss: 0.1044 - acc: 0.9747 - val_loss: 0.1032 - val_acc: 0.9727\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0530 - acc: 0.9805\n",
            " - 11s - loss: 0.1568 - acc: 0.9708 - val_loss: 0.0530 - val_acc: 0.9805\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0064 - acc: 1.0000\n",
            " - 11s - loss: 0.0638 - acc: 0.9815 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0111 - acc: 0.9961\n",
            " - 11s - loss: 0.1017 - acc: 0.9708 - val_loss: 0.0111 - val_acc: 0.9961\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0540 - acc: 0.9766\n",
            " - 11s - loss: 0.1719 - acc: 0.9640 - val_loss: 0.0540 - val_acc: 0.9766\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0113 - acc: 0.9922\n",
            " - 11s - loss: 0.0592 - acc: 0.9844 - val_loss: 0.0113 - val_acc: 0.9922\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0782 - acc: 0.9688\n",
            " - 11s - loss: 0.0517 - acc: 0.9854 - val_loss: 0.0782 - val_acc: 0.9688\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.3089 - acc: 0.9414\n",
            " - 11s - loss: 0.0517 - acc: 0.9844 - val_loss: 0.3089 - val_acc: 0.9414\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2673 - acc: 0.9375\n",
            " - 11s - loss: 0.3747 - acc: 0.9649 - val_loss: 0.2673 - val_acc: 0.9375\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0427 - acc: 0.9844\n",
            " - 11s - loss: 0.0800 - acc: 0.9796 - val_loss: 0.0427 - val_acc: 0.9844\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0098 - acc: 0.9961\n",
            " - 11s - loss: 0.1284 - acc: 0.9718 - val_loss: 0.0098 - val_acc: 0.9961\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1433 - acc: 0.9609\n",
            " - 11s - loss: 0.0943 - acc: 0.9718 - val_loss: 0.1433 - val_acc: 0.9609\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0012 - acc: 1.0000\n",
            " - 11s - loss: 0.0661 - acc: 0.9825 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 8.0679e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0871 - acc: 0.9708 - val_loss: 8.0679e-04 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1171 - acc: 0.9648\n",
            " - 11s - loss: 0.0584 - acc: 0.9796 - val_loss: 0.1171 - val_acc: 0.9648\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.2980 - acc: 0.9219\n",
            " - 11s - loss: 0.0689 - acc: 0.9805 - val_loss: 0.2980 - val_acc: 0.9219\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 1.1360e-05 - acc: 1.0000\n",
            " - 11s - loss: 0.0659 - acc: 0.9805 - val_loss: 1.1360e-05 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 2.5343e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0913 - acc: 0.9776 - val_loss: 2.5343e-04 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0059 - acc: 0.9961\n",
            " - 11s - loss: 0.0466 - acc: 0.9815 - val_loss: 0.0059 - val_acc: 0.9961\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0037 - acc: 0.9961\n",
            " - 11s - loss: 0.1286 - acc: 0.9766 - val_loss: 0.0037 - val_acc: 0.9961\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0058 - acc: 0.9961\n",
            " - 11s - loss: 0.0406 - acc: 0.9864 - val_loss: 0.0058 - val_acc: 0.9961\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1532 - acc: 0.9570\n",
            " - 11s - loss: 0.2544 - acc: 0.9727 - val_loss: 0.1532 - val_acc: 0.9570\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0268 - acc: 0.9961\n",
            " - 11s - loss: 0.0437 - acc: 0.9893 - val_loss: 0.0268 - val_acc: 0.9961\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0200 - acc: 0.9961\n",
            " - 11s - loss: 0.1043 - acc: 0.9737 - val_loss: 0.0200 - val_acc: 0.9961\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.6372 - acc: 0.8750\n",
            " - 11s - loss: 0.0707 - acc: 0.9825 - val_loss: 0.6372 - val_acc: 0.8750\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0081 - acc: 0.9961\n",
            " - 11s - loss: 0.0614 - acc: 0.9864 - val_loss: 0.0081 - val_acc: 0.9961\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0483 - acc: 0.9961\n",
            " - 11s - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0483 - val_acc: 0.9961\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 5.0879 - acc: 0.5820\n",
            " - 11s - loss: 0.0625 - acc: 0.9776 - val_loss: 5.0879 - val_acc: 0.5820\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.7809 - acc: 0.8711\n",
            " - 11s - loss: 0.0371 - acc: 0.9873 - val_loss: 0.7809 - val_acc: 0.8711\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1038 - acc: 0.9766\n",
            " - 11s - loss: 0.1836 - acc: 0.9757 - val_loss: 0.1038 - val_acc: 0.9766\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0559 - acc: 0.9766\n",
            " - 11s - loss: 0.0767 - acc: 0.9805 - val_loss: 0.0559 - val_acc: 0.9766\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 2.9439 - acc: 0.6914\n",
            " - 11s - loss: 0.0632 - acc: 0.9815 - val_loss: 2.9439 - val_acc: 0.6914\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 1.8400e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.1129 - acc: 0.9796 - val_loss: 1.8400e-04 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.3944 - acc: 0.9219\n",
            " - 11s - loss: 0.1949 - acc: 0.9698 - val_loss: 0.3944 - val_acc: 0.9219\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1232 - acc: 0.9883\n",
            " - 11s - loss: 0.1174 - acc: 0.9708 - val_loss: 0.1232 - val_acc: 0.9883\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1239 - acc: 0.9648\n",
            " - 11s - loss: 0.1856 - acc: 0.9649 - val_loss: 0.1239 - val_acc: 0.9648\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0066 - acc: 0.9922\n",
            " - 11s - loss: 0.1130 - acc: 0.9776 - val_loss: 0.0066 - val_acc: 0.9922\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.4547 - acc: 0.9102\n",
            " - 11s - loss: 0.0403 - acc: 0.9873 - val_loss: 0.4547 - val_acc: 0.9102\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1843 - acc: 0.9492\n",
            " - 11s - loss: 0.0727 - acc: 0.9805 - val_loss: 0.1843 - val_acc: 0.9492\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.5111 - acc: 0.9102\n",
            " - 11s - loss: 0.0633 - acc: 0.9825 - val_loss: 0.5111 - val_acc: 0.9102\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1473 - acc: 0.9570\n",
            " - 11s - loss: 0.0686 - acc: 0.9766 - val_loss: 0.1473 - val_acc: 0.9570\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1131 - acc: 0.9609\n",
            " - 11s - loss: 0.0408 - acc: 0.9864 - val_loss: 0.1131 - val_acc: 0.9609\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.2105 - acc: 0.9570\n",
            " - 11s - loss: 0.0923 - acc: 0.9805 - val_loss: 0.2105 - val_acc: 0.9570\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0387 - acc: 0.9961\n",
            " - 11s - loss: 0.0421 - acc: 0.9825 - val_loss: 0.0387 - val_acc: 0.9961\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0206 - acc: 0.9922\n",
            " - 11s - loss: 0.0603 - acc: 0.9844 - val_loss: 0.0206 - val_acc: 0.9922\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0011 - acc: 1.0000\n",
            " - 11s - loss: 0.1105 - acc: 0.9757 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 5.1736e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0788 - acc: 0.9805 - val_loss: 5.1736e-04 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0930 - acc: 0.9805\n",
            " - 11s - loss: 0.1099 - acc: 0.9873 - val_loss: 0.0930 - val_acc: 0.9805\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0592 - acc: 0.9766\n",
            " - 11s - loss: 0.2700 - acc: 0.9766 - val_loss: 0.0592 - val_acc: 0.9766\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.2422 - acc: 0.9688\n",
            " - 11s - loss: 0.2209 - acc: 0.9805 - val_loss: 0.2422 - val_acc: 0.9688\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.2166 - acc: 0.9570\n",
            " - 11s - loss: 0.0996 - acc: 0.9796 - val_loss: 0.2166 - val_acc: 0.9570\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1056 - acc: 0.9609\n",
            " - 11s - loss: 0.1428 - acc: 0.9834 - val_loss: 0.1056 - val_acc: 0.9609\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0315 - acc: 0.9961\n",
            " - 11s - loss: 0.1890 - acc: 0.9766 - val_loss: 0.0315 - val_acc: 0.9961\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0198 - acc: 0.9961\n",
            " - 11s - loss: 0.1049 - acc: 0.9844 - val_loss: 0.0198 - val_acc: 0.9961\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0623 - acc: 0.9961\n",
            " - 11s - loss: 0.3134 - acc: 0.9796 - val_loss: 0.0623 - val_acc: 0.9961\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0315 - acc: 0.9961\n",
            " - 11s - loss: 0.0429 - acc: 0.9864 - val_loss: 0.0315 - val_acc: 0.9961\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.6723 - acc: 0.8984\n",
            " - 11s - loss: 0.0468 - acc: 0.9854 - val_loss: 0.6723 - val_acc: 0.8984\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0561 - acc: 0.9961\n",
            " - 11s - loss: 0.0405 - acc: 0.9883 - val_loss: 0.0561 - val_acc: 0.9961\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.3805 - acc: 0.9297\n",
            " - 11s - loss: 0.0328 - acc: 0.9903 - val_loss: 0.3805 - val_acc: 0.9297\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1848 - acc: 0.9414\n",
            " - 11s - loss: 0.0486 - acc: 0.9834 - val_loss: 0.1848 - val_acc: 0.9414\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0157 - acc: 0.9883\n",
            " - 11s - loss: 0.0612 - acc: 0.9825 - val_loss: 0.0157 - val_acc: 0.9883\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.5460 - acc: 0.9180\n",
            " - 11s - loss: 0.1120 - acc: 0.9776 - val_loss: 0.5460 - val_acc: 0.9180\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0279 - acc: 0.9961\n",
            " - 11s - loss: 0.1197 - acc: 0.9776 - val_loss: 0.0279 - val_acc: 0.9961\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0320 - acc: 0.9961\n",
            " - 11s - loss: 0.2371 - acc: 0.9776 - val_loss: 0.0320 - val_acc: 0.9961\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0879 - acc: 0.9844\n",
            " - 11s - loss: 0.0413 - acc: 0.9864 - val_loss: 0.0879 - val_acc: 0.9844\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1777 - acc: 0.9766\n",
            " - 11s - loss: 0.0512 - acc: 0.9873 - val_loss: 0.1777 - val_acc: 0.9766\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1493 - acc: 0.9609\n",
            " - 11s - loss: 0.0457 - acc: 0.9844 - val_loss: 0.1493 - val_acc: 0.9609\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.2100 - acc: 0.9570\n",
            " - 11s - loss: 0.1457 - acc: 0.9796 - val_loss: 0.2100 - val_acc: 0.9570\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1164 - acc: 0.9688\n",
            " - 11s - loss: 0.0527 - acc: 0.9854 - val_loss: 0.1164 - val_acc: 0.9688\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.1448 - acc: 0.9609\n",
            " - 11s - loss: 0.2133 - acc: 0.9786 - val_loss: 0.1448 - val_acc: 0.9609\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0653 - acc: 0.9805\n",
            " - 11s - loss: 0.0933 - acc: 0.9864 - val_loss: 0.0653 - val_acc: 0.9805\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0565 - acc: 0.9844\n",
            " - 11s - loss: 0.0588 - acc: 0.9834 - val_loss: 0.0565 - val_acc: 0.9844\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1616 - acc: 0.9844\n",
            " - 11s - loss: 0.0580 - acc: 0.9805 - val_loss: 0.1616 - val_acc: 0.9844\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0324 - acc: 0.9883\n",
            " - 11s - loss: 0.0631 - acc: 0.9834 - val_loss: 0.0324 - val_acc: 0.9883\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.1219 - acc: 0.9648\n",
            " - 11s - loss: 0.0391 - acc: 0.9873 - val_loss: 0.1219 - val_acc: 0.9648\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0189 - acc: 0.9922\n",
            " - 11s - loss: 0.0552 - acc: 0.9825 - val_loss: 0.0189 - val_acc: 0.9922\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.8958 - acc: 0.8867\n",
            " - 11s - loss: 0.0511 - acc: 0.9854 - val_loss: 0.8958 - val_acc: 0.8867\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0816 - acc: 0.9766\n",
            " - 11s - loss: 0.0569 - acc: 0.9883 - val_loss: 0.0816 - val_acc: 0.9766\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0238 - acc: 0.9961\n",
            " - 11s - loss: 0.0460 - acc: 0.9864 - val_loss: 0.0238 - val_acc: 0.9961\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 9.4343e-04 - acc: 1.0000\n",
            " - 11s - loss: 0.0607 - acc: 0.9786 - val_loss: 9.4343e-04 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0250 - acc: 0.9922\n",
            " - 11s - loss: 0.0908 - acc: 0.9786 - val_loss: 0.0250 - val_acc: 0.9922\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 0.0135 - acc: 0.9961\n",
            " - 11s - loss: 0.0416 - acc: 0.9903 - val_loss: 0.0135 - val_acc: 0.9961\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0971 - acc: 0.9648\n",
            " - 11s - loss: 0.0637 - acc: 0.9854 - val_loss: 0.0971 - val_acc: 0.9648\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0010 - acc: 1.0000\n",
            " - 11s - loss: 0.1053 - acc: 0.9757 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.4774 - acc: 0.9336\n",
            " - 11s - loss: 0.0285 - acc: 0.9922 - val_loss: 0.4774 - val_acc: 0.9336\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.0016 - acc: 1.0000\n",
            " - 11s - loss: 0.0361 - acc: 0.9912 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 0.1051 - acc: 0.9922\n",
            " - 11s - loss: 0.0407 - acc: 0.9922 - val_loss: 0.1051 - val_acc: 0.9922\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0623 - acc: 0.9844\n",
            " - 11s - loss: 0.1011 - acc: 0.9747 - val_loss: 0.0623 - val_acc: 0.9844\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 0.0279 - acc: 0.9961\n",
            " - 11s - loss: 0.0580 - acc: 0.9844 - val_loss: 0.0279 - val_acc: 0.9961\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.1157 - acc: 0.9688\n",
            " - 11s - loss: 0.1419 - acc: 0.9864 - val_loss: 0.1157 - val_acc: 0.9688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "64d9c947-f126-426c-c5b8-de60bf91f3d0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWhPKfRKbRvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}